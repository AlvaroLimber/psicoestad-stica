# Estadística Teórica

La **estadística teórica** proporciona los fundamentos matemáticos que sustentan la inferencia estadística. A través de la **probabilidad**, los **modelos de distribución** y los **teoremas fundamentales**, permite cuantificar la incertidumbre y estimar parámetros poblacionales a partir de muestras. En su aspecto teórico, permite establecer y entender la relación entre la **Población Objetivo (P.O.)** y la **muestra** (@LSJ2025; @Moore2013). Habla sobre la probabilidad y la variable aleatoria, caracterizada por el azar, e implica las distribuciones muestrales, donde se conecta con la práctica y la realidad.

## Fundamentos de Probabilidad y Axiomas

La **probabilidad** es una **medida de incertidumbre** y constituye la base teórica de la inferencia estadística (@Feller1968).

### Experimento Aleatorio y Espacio Muestral

Un **experimento aleatorio** es un proceso del cual **NO se conoce el resultado** antes de su realización. Los conceptos de aleatorio e incertidumbre están relacionados.

*Ejemplo en Psicología:* Observar si un paciente abandona la terapia ($X=1$) o la continúa ($X=0$).

El **espacio muestral ($\Omega$)** es el conjunto de **TODOS** los resultados posibles que puede arrojar un experimento aleatorio.

* **Espacio Muestral Discreto:** Si $\Omega$ es finito o contablemente infinito.
    * *Ejemplo:* Medir la **calificación** obtenida en un examen (valores posibles: 0, 1, 2, ..., 10). $\Omega = \{0, 1, 2, \dots, 10\}$.

* **Espacio Muestral Continuo:** Si $\Omega$ incluye todos los valores dentro de un intervalo (no contable).
    * *Ejemplo 3:* Medir el **tiempo de reacción** (en segundos) de una persona a un estímulo visual. $\Omega = [0, \infty)$.

Un **evento ($A$)** es cualquier subconjunto del espacio muestral ($\Omega$). Es la ocurrencia o no ocurrencia de un resultado específico o grupo de resultados. Cuando un evento es imposible, su probabilidad es **igual a 0**.

* *Ejemplo de Evento (basado en Ejemplo 1, calificación):*
    * Evento $A$: Aprobar el examen (obtener una calificación mayor a 5). $A = \{6, 7, 8, 9, 10\}$.
    * Evento $B$: Obtener una calificación perfecta. $B = \{10\}$.

### Axiomas de la Probabilidad (Kolmogórov)

Formalmente, un espacio probabilístico $(\Omega, \mathcal{A}, P)$ se define con base en los axiomas:

1.  **No negatividad**: La probabilidad de cualquier evento $A$ debe estar **entre 0 y 1**. $P(A) \ge 0$.
2.  **Unidad**: La probabilidad del espacio muestral siempre es **igual a 1**. $P(\Omega) = 1$.
3.  **Aditividad**: Para una secuencia de eventos mutuamente excluyentes ($A_1, A_2, ...$), la probabilidad de su unión es la suma de sus probabilidades:
    $$
    P\left(\bigcup_i A_i\right) = \sum_i P(A_i)
    $$

### Enfoques Conceptuales de la Probabilidad

Existen tres enfoques principales para interpretar la probabilidad, cada uno con implicaciones distintas en la aplicación de la estadística (@LSJ2025; @Moore2013):

#### Probabilidad Teórica (Clásica)

Deriva del razonamiento lógico o combinatorio y asume que todos los resultados posibles son **igualmente probables (equiprobables)**.

$$
P(A) = \frac{\text{número de casos favorables}}{\text{número total de casos posibles}}
$$

* **Desarrollo:** Este enfoque es útil principalmente para experimentos ideales, juegos de azar o situaciones muy controladas donde la simetría de los resultados es evidente. Es la definición más limitada en las ciencias empíricas como la psicología, pues rara vez se asume equiprobabilidad en los fenómenos de la vida real.
* *Ejemplo en Psicología:* Asumir la probabilidad de que un sujeto elija la Opción A o la Opción B en un test simple sin sesgos previos es $P(A) = 1/2$.

#### Probabilidad Frecuentista (Empírica)

Se define como el **límite de la frecuencia relativa** con que ocurre un evento en un número grande de repeticiones independientes del experimento.

$$
P(A) = \lim_{n \to \infty} \frac{f_A}{n}
$$

* **Desarrollo:** Es el enfoque más relevante y utilizado en la inferencia estadística clásica y en la investigación psicológica. La probabilidad se estima a partir de la **observación empírica y la experiencia acumulada**. La precisión de la estimación mejora a medida que aumenta el número de observaciones ($n \to \infty$), tal como lo establece la **Ley de los Grandes Números**.
* *Ejemplo en Psicología:* Si se observa que de 1,000 pacientes con un trastorno específico, 650 responden positivamente a un tipo de terapia, la probabilidad frecuentista de respuesta positiva es $P(\text{Respuesta Positiva}) \approx 650/1000 = 0.65$.

#### Probabilidad Bayesiana (Subjetiva o Condicional)

Interpreta la probabilidad como el **grado de creencia racional** sobre la ocurrencia de un evento, dado un conjunto de evidencias.
* **Desarrollo:** Parte de una **probabilidad inicial** (*a priori*) que se ajusta y se actualiza mediante nueva evidencia (datos) para generar una **Probabilidad Posterior** más precisa. Se formaliza mediante el **Teorema de Bayes**.

$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$

## Variable Aleatoria y Distribuciones

### Variable Aleatoria (v.a. = X)

Una **variable aleatoria (X)** es una función que asigna a los eventos posibles una medida cuantificable. Es el soporte cuantitativo para las probabilidades.

La distinción entre $X$ (mayúscula) y $x$ (minúscula) es crucial:
* **$X$ (Mayúscula)**: Representa la **variable aleatoria** en sí, es decir, la *regla* o *función* que describe el conjunto de resultados posibles. Es la variable **antes** de que se realice el experimento.
* **$x$ (Minúscula)**: Representa una **realización** o un **valor específico** que la variable aleatoria $X$ puede tomar después de que el experimento ha ocurrido. Es un resultado concreto del recorrido.

*Ejemplo en Psicología:*
* **Variable Aleatoria ($X$)**: El **Puntaje de Ansiedad** que obtendrá un sujeto en el próximo test.
* **Realización ($x$)**: El puntaje de 42 que *obtuvo* el sujeto al completar el test.

La probabilidad se define como la posibilidad de que la variable aleatoria $X$ tome un valor específico $x$: $P(X = x)$.

### Distribuciones Discretas

Las distribuciones discretas describen variables aleatorias cuyo recorrido es finito o contable (valores enteros, no continuos).

#### Experimento y Variable Aleatoria Bernoulli

Un **Experimento Bernoulli** es el modelo de probabilidad más simple. Solo tiene **dos resultados posibles** mutuamente excluyentes: **éxito** ($X=1$) o **fracaso** ($X=0$). La probabilidad de éxito ($p$) se mantiene constante en cada ensayo.

* **Fórmula (Función de Masa de Probabilidad):**
    $$
    P(X = x) = p^x (1-p)^{1-x} \quad \text{para } x \in \{0, 1\}
    $$
* *Ejemplo en Psicología:* Determinar si un paciente **abandona la terapia** (éxito, $X=1$) o **continúa** (fracaso, $X=0$). Si la probabilidad histórica de abandono es $p=0.3$, entonces $P(X=1) = 0.3$ y $P(X=0) = 0.7$.

#### Distribución y Experimento Binomial

Un **Experimento Binomial** es una **serie de $n$ repeticiones independientes del experimento Bernoulli**. La **Distribución Binomial** cuenta cuántos **éxitos** ($x$) ocurren en ese número fijo de intentos ($n$) con una probabilidad de éxito $p$ constante.

* **Fórmula (Función de Masa de Probabilidad):**
    $$
    P(X = x) = \binom{n}{x} p^x (1-p)^{n-x} \quad \text{para } x \in \{0, 1, \dots, n\}
    $$
    donde $\binom{n}{x} = \frac{n!}{x!(n-x)!}$ es el número de formas de obtener $k$ éxitos en $n$ intentos.

* **Valor Esperado (Media) de la Binomial**
    El **Valor Esperado** o **Esperanza Matemática** ($E[X]$) de una variable aleatoria es el promedio teórico a largo plazo si el experimento se repite un número infinito de veces. Para la distribución Binomial, representa el número esperado de éxitos.
    $$
    E[X] = n \cdot p
    $$

* *Ejemplo Completo en Psicología:*
    Una investigadora aplica un test de **razonamiento moral** con $n=20$ ítems (preguntas de sí/no). Asume que la probabilidad de responder correctamente al azar es $p=0.5$.
    1. **Valor Esperado:** El número esperado de respuestas correctas (por azar) es:
        $$
        E[X] = n \cdot p = 20 \cdot 0.5 = 10
        $$
        Se espera que, en promedio, una persona que responda al azar acierte 10 de las 20 preguntas.
    2. **Cálculo de Probabilidad:** Si la investigadora quiere saber la probabilidad de que un sujeto responda **exactamente 15** preguntas correctamente al azar ($x=15$):
        $$
        P(X = 15) = \binom{20}{15} (0.5)^{15} (1-0.5)^{20-15}
        $$
        $$
        P(X = 15) = 15504 \cdot (0.0000305) \cdot (0.03125) \approx 0.0148
        $$
        La probabilidad de obtener exactamente 15 aciertos al azar es muy baja (aproximadamente 1.48%). Esto permite a la investigadora inferir que un puntaje superior a 10 o 11 probablemente no se deba solo al azar.

### Distribución Normal (Campana de Gauss)

La **Distribución Normal** (o **Campana de Gauss**) es la distribución de probabilidad continua más importante en estadística inferencial. Describe variables que tienden a concentrarse simétricamente alrededor de un valor central, disminuyendo su frecuencia hacia los extremos.

* **Fórmula (Función de Densidad de Probabilidad):**
    $$
    f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
    $$
    Esta fórmula establece que la forma de la campana está completamente determinada por dos parámetros: la **media ($\mu$)** (que define la posición central) y la **desviación estándar ($\sigma$)** (que define la dispersión o altura).

* **Propiedades Clave:**
    1.  **Forma de Campana:** Es perfectamente simétrica respecto a la media. En el punto central, la media, la mediana y la moda coinciden ($\mu$).
    2.  **Determinada por $\mu$ y $\sigma$**: Cambios en $\mu$ desplazan la curva horizontalmente, mientras que cambios en $\sigma$ la hacen más ancha (mayor dispersión) o más estrecha (menor dispersión).
    3.  **Regla Empírica (68-95-99.7):** Un porcentaje predecible de los datos cae dentro de ciertos rangos respecto a la media:
        * Aproximadamente el **68%** de los datos se encuentra a $\pm 1$ desviación estándar ($\mu \pm 1\sigma$).
        * Aproximadamente el **95%** de los datos se encuentra a $\pm 2$ desviaciones estándar ($\mu \pm 2\sigma$).
        * Aproximadamente el **99.7%** de los datos se encuentra a $\pm 3$ desviaciones estándar ($\mu \pm 3\sigma$).

*Ejemplo en Psicología:* Las puntuaciones del **Coeficiente Intelectual (CI)** en grandes poblaciones siguen aproximadamente una distribución normal con $\mu=100$ y $\sigma=15$. Esto implica que, basándose en la regla empírica, el 95% de la población tiene un CI entre 70 y 130 (100 $\pm$ $2 \times 15$).

## Muestreo, Teoremas Fundamentales y Estimación

### Muestreo e Inferencia Estadística

El **muestreo** es la forma de extraer una muestra. Es fundamental porque el objetivo principal de la estadística es la **Inferencia Estadística**: el proceso de utilizar información limitada de una muestra para sacar conclusiones o hacer generalizaciones sobre una población más grande.

#### Concepto de Muestra y Población

* **Población Objetivo (P.O.)**: Es el conjunto completo de elementos, individuos o eventos sobre los cuales el investigador desea obtener información y generalizar sus conclusiones.
* **Muestra**: Es un **subconjunto (o "pedacito")** de la Población Objetivo que realmente se observa y mide en el estudio. La muestra se usa como sustituto de la P.O. por razones prácticas (costo, tiempo, imposibilidad de medir a todos).

#### El Rol del Muestreo Aleatorio

Para que el proceso de inferencia sea válido, el muestreo debe ser **aleatorio**.
* **Muestreo Aleatorio**: Incorpora el **azar** en la selección, asegurando que cada unidad de la P.O. tenga una probabilidad conocida (y usualmente igual) de ser incluida en la muestra.
    * **Importancia**: Un muestreo aleatorio minimiza el **sesgo** y es la única condición bajo la cual los principios de la probabilidad (como el Teorema del Límite Central) pueden aplicarse, permitiendo que la muestra sea **representativa** de la población.
* **Muestreo No Aleatorio**: Se basa en la conveniencia, accesibilidad o juicio del investigador, lo que **limita o anula** la capacidad de generalizar estadísticamente a la P.O.

#### Conceptos de Estimación

La **Estimación** es la actividad central de la inferencia, donde el investigador busca aproximar un valor desconocido de la población (el **Parámetro**) usando el dato conocido de la muestra (el **Estimador**).

| Concepto | Definición | Conexión con la Inferencia | Símbolo |
| :--- | :--- | :--- | :--- |
| **Parámetro** | Una medida descriptiva calculada sobre la **P.O.**. Fijo, único, pero generalmente **desconocido**. | Es el **objetivo** de la inferencia; lo que queremos descubrir. | $\theta$ (ej. $\mu$) |
| **Estimador** | La medida análoga calculada sobre la **MUESTRA**. Es una variable aleatoria que **varía de muestra a muestra**. | Es la **herramienta** de la inferencia; lo que usamos para aproximar el parámetro. | $\hat{\theta}$ (ej. $\bar{X}$) |

***Ejemplo General: Nivel de Burnout en Psicólogos***

* **Población Objetivo (P.O.):** Todos los psicólogos colegiados de una región.
* **Muestra:** Se selecciona aleatoriamente un grupo de 150 psicólogos para la encuesta.
* **Parámetro ($\mu$):** La media real (desconocida) del nivel de *burnout* de **todos** los psicólogos de la región.
* **Estimador ($\bar{X}$):** La media del nivel de *burnout* calculada a partir de la muestra de 150 psicólogos (Ej: $\bar{X}=35.2$). El objetivo es usar $\bar{X}=35.2$ para inferir el valor de $\mu$.

El proceso de inferencia busca evaluar la **calidad** y **precisión** del estimador ($\hat{\theta}$) en su intento de acercarse al verdadero valor del parámetro ($\theta$).

### Distribuciones Muestrales

Una **Distribución Muestral** es la distribución de probabilidad de un **estadístico** (como la media $\bar{X}$ o la proporción $\hat{p}$) cuando ese estadístico se calcula a partir de **todas las posibles muestras** de un tamaño fijo ($n$) que se pueden extraer de una población.

* **Diferencia Clave:** Una distribución de probabilidad describe cómo se comporta una variable **individual** ($X$), mientras que la distribución muestral describe cómo se comporta un **estimador** ($\hat{\theta}$) de muestra a muestra.

#### Distribución Muestral de la Media ($\bar{X}$)

La distribución muestral de la media es fundamental. Dos propiedades clave, derivadas de los teoremas fundamentales, definen su comportamiento:

1.  **Media de la Distribución Muestral ($\mu_{\bar{X}}$):**
    El promedio de todas las medias muestrales posibles es igual a la media poblacional. Esto asegura que la media muestral es un estimador **insesgado**.
    $$
    \mu_{\bar{X}} = \mu
    $$

2.  **Error Estándar ($\sigma_{\bar{X}}$):**
    La desviación estándar de la distribución muestral de la media se llama **Error Estándar**. Mide la **variabilidad** (la precisión) del estimador $\bar{X}$.
    $$
    \sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}
    $$

> Ejemplo: Gastos de Transporte

Consideremos una **población pequeña ($N=5$)** de estudiantes universitarios con los siguientes gastos diarios de transporte (en Bs.): $X = \{2, 4, 6, 8, 10\}$.

1.  **Parámetro Poblacional ($\mu$):**
    $$\mu = \frac{2 + 4 + 6 + 8 + 10}{5} = \mathbf{6}$$

2.  **Muestreo ($n=3$):**
    Se extraen **todas** las posibles muestras de tamaño $n=3$. Existen $\binom{5}{3} = 10$ muestras posibles.

| Muestra | Gastos ($X$) | Media Muestral ($\bar{X}$) |
|:---:|:---:|:---:|
| 1 | {2, 4, 6} | 4.00 |
| 2 | {2, 4, 8} | 4.67 |
| 3 | {2, 4, 10} | 5.33 |
| 4 | {2, 6, 8} | 5.33 |
| 5 | {2, 6, 10} | 6.00 |
| 6 | {2, 8, 10} | 6.67 |
| 7 | {4, 6, 8} | 6.00 |
| 8 | {4, 6, 10} | 6.67 |
| 9 | {4, 8, 10} | 7.33 |
| 10 | {6, 8, 10} | 8.00 |

3.  **Verificación de la Media Muestral ($\mu_{\bar{X}}$):**
    El promedio de las 10 medias muestrales es:
    $$\mu_{\bar{X}} = \frac{4.00 + \dots + 8.00}{10} = \frac{60}{10} = \mathbf{6}$$

**Conclusión del Ejemplo:**
Se confirma que la **media de la distribución muestral ($\mu_{\bar{X}}=6$) es idéntica a la media poblacional ($\mu=6$)**. Las medias de las muestras individuales ($\bar{X}$) varían, pero su promedio exacto es el verdadero parámetro poblacional. El **Error Estándar** sería la desviación de estos 10 valores de $\bar{X}$ respecto a 6.

### Ley de los Grandes Números (LGN)

Establece que, a medida que el tamaño de la muestra ($n$) aumenta, la media muestral ($\bar{X}$) se aproxima cada vez más a la media poblacional ($\mu$) (@Moore2013).

$$
\lim_{n \to \infty} P(|\bar{X} - \mu| < \varepsilon) = 1
$$
*Aplicación:* Para tener una estimación precisa del nivel promedio de **satisfacción laboral** en una empresa, se necesitan encuestar a muchos empleados. Cuanto mayor sea $n$, más cerca estará $\bar{X}$ del valor real $\mu$.

### Teorema del Límite Central (TLC)

Si se toma una **muestra aleatoria suficientemente grande** ($n>20$) de **cualquier población**, la distribución de la **media muestral ($\bar{X}$)** tenderá a ser **aproximadamente normal** (@LSJ2025).

La media muestral estandarizada sigue una distribución normal estándar:

$$
Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)
$$

## Estimación de Parámetros

La **Estimación** es el proceso de aproximar un valor desconocido de la población ($\theta$) usando el dato de la muestra ($\hat{\theta}$).

### Estimación Puntual para la Media

Se utiliza un **valor único** (el estadístico muestral) como la mejor aproximación del parámetro poblacional.

$$
\hat{\mu} = \bar{X}
$$

*Ejemplo:* Si la media de **autoeficacia percibida** en una muestra de 50 estudiantes es $\bar{X} = 75$, la estimación puntual de la media poblacional ($\mu$) es 75.

### Estimación por Intervalo de Confianza (IC) para la Media

Es un **rango de valores** que probablemente contiene el parámetro poblacional con un **nivel de confianza ($1-\alpha$)** determinado.

Si $\sigma$ es conocida:

$$
IC_{(1-\alpha)} = \bar{X} \pm Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}
$$

* **Valores de $Z_{\alpha/2}$ para niveles de confianza comunes:**
    * **90% de Confianza**: $Z_{\alpha/2} = 1.645$
    * **95% de Confianza**: $Z_{\alpha/2} = 1.96$
    * **99% de Confianza**: $Z_{\alpha/2} = 2.576$ (o 2.58)

*Ejemplo:* Un IC al 95% para la media de **estrés postraumático** es $(24.3, 27.1)$. Esto significa que si repitiéramos el muestreo muchas veces, el 95% de los intervalos construidos contendrían la verdadera media poblacional.

Si $\sigma$ no se conoce se la estima mediante la desviación estándar $s$. 

### Pruebas de Hipótesis

Una **Prueba de Hipótesis** es un procedimiento estadístico formalizado para tomar una decisión sobre un parámetro poblacional, al contrastar dos afirmaciones opuestas usando la evidencia de la muestra. Permite determinar si una creencia o conjetura ($\hat{\theta}$) está justificada por los datos.

#### Pasos de la Prueba de Hipótesis (General)

El procedimiento general sigue una estructura de cuatro pasos:

1.  **Formular Hipótesis ($H_0$ y $H_a$)**: Se establecen la afirmación que se quiere probar (nula) y su alternativa.
2.  **Establecer Nivel de Significación ($\alpha$)**: Se define la probabilidad máxima que estamos dispuestos a aceptar de cometer un Error de Tipo I (generalmente $\alpha=0.05$ o $0.01$).
3.  **Construir el Estadístico de Prueba**: Se calcula el valor estandarizado (ej. $Z$, $t$) que mide cuán lejos está el estimador muestral del valor propuesto en $H_0$.
4.  **Evaluar y Concluir**: Se compara el estadístico de prueba con los valores críticos o se usa el $P$-valor para decidir si se **rechaza** o **no se rechaza** la Hipótesis Nula.

#### Formulación de Hipótesis

1.  **Hipótesis Nula ($H_0$)**: Es la afirmación que se quiere probar y la que asume que **no hay efecto, cambio o diferencia**. Siempre incluye un signo de igualdad (Ej: $\mu = 10$).
2.  **Hipótesis Alternativa ($H_a$)**: Es la afirmación **contraria a la nula**. Es lo que se sospecha o se quiere demostrar.
    * **Prueba Bilateral**: $H_a: \mu \ne 10$
    * **Prueba Unilateral a la Derecha**: $H_a: \mu > 10$
    * **Prueba Unilateral a la Izquierda**: $H_a: \mu < 10$

#### Errores en la Prueba de Hipótesis

El objetivo es minimizar la probabilidad de cometer estos errores:

| Tipo de Error | Definición | Consecuencia (Riesgo Controlado) |
| :--- | :--- | :--- |
| **Error de Tipo I ($\alpha$)** | **Rechazar** la hipótesis nula ($H_0$) cuando en realidad es **verdadera**. | Falso Positivo. Se controla con el nivel de significación ($\alpha$). |
| **Error de Tipo II ($\beta$)** | **No rechazar** la hipótesis nula ($H_0$) cuando en realidad es **falsa**. | Falso Negativo. Se relaciona con la potencia de la prueba ($1-\beta$). |

#### Prueba de Hipótesis para la Media ($\mu$)

Se utiliza para probar si la media poblacional ($\mu$) es igual a un valor conocido ($ \mu_0 $). El estadístico de prueba (generalmente $Z$ o $t$) mide la distancia de la media muestral ($\bar{X}$) a $\mu_0$ en términos de errores estándar.

**Estadístico de Prueba (para la media con $\sigma$ conocida):**

$$
Z_{0} = \frac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}
$$
Para pruebas bilaterales, la decisión; Se rechaza $H_0$ cuando:
  
$$Z_0>Z_{\alpha/2} \quad ó \quad Z_0<-Z_{\alpha/2}$$

Los valores usuales para los $Z_{\alpha/2}$ son:

+ al 10 de significanca: $Z_{\alpha/2}=1.64$
+ al 5 de significanca: $Z_{\alpha/2}=1.96$
+ al 1 de significanca: $Z_{\alpha/2}=2.58$

Para las pruebas unilaterales se utiliza el mismo estadístico de prueba $Z_0$, con las siguientes hipótesis y región de rechazo.

$$H_0: \mu=\mu_0$$
$$H_1: \mu>\mu_0$$
Se rechaza $H_0$ si $Z_0>Z{\alpha}$. 

$$H_0: \mu=\mu_0$$

$$H_1: \mu < \mu_0$$
Se rechaza $H_0$ si $Z_0<-Z{\alpha}$

Los valores usuales para los $Z_{\alpha}$ de pruebas unilaterales.

  + $Z_{0.1}=1.28$
  + $Z_{0.05}=1.64$
  + $Z_{0.01}=2.33$

## Tamaño de Muestra

El cálculo del **tamaño de muestra ($n$)** es uno de los pasos iniciales más críticos en cualquier investigación que emplee muestreo, pues define la capacidad del estudio para obtener conclusiones válidas y precisas.

### Relevancia de la Aleatoriedad y el Equilibrio Logístico

* **Pertinencia del Cálculo:** El cálculo del tamaño de muestra solo tiene sentido y validez cuando se utiliza un **muestreo aleatorio**. Si la muestra es no aleatoria (por conveniencia), la inferencia estadística está comprometida, independientemente del tamaño calculado.
* **Balance Estadístico vs. Logístico:** Determinar $n$ requiere un equilibrio entre:
    * **Necesidad Estadística:** El tamaño mínimo requerido para alcanzar la precisión deseada (reducir el error estándar o aumentar la potencia).
    * **Factibilidad Logística:** Los recursos disponibles (tiempo, costo, personal) para recolectar los datos.

### Cálculo para Fines de Inferencia Descriptiva (Margen de Error)

Para la inferencia descriptiva, el cálculo se basa en el **margen de error ($e$)** o precisión deseada, que es la máxima diferencia aceptable entre el estimador muestral ($\hat{\theta}$) y el parámetro poblacional ($\theta$).

#### Cálculo para la Media

Se utiliza cuando se desea estimar el promedio ($\mu$).
$$
n = \frac{Z^2 \cdot \sigma^2}{e^2}=\left(\frac{z*\sigma}{e}\right)^2
$$
Donde:
* $Z$: Valor crítico asociado al nivel de confianza deseado.
* $\sigma^2$: Varianza de la población (a menudo estimada mediante estudios piloto o valores conservadores).
* $e$: Margen de error o precisión máxima aceptable.

#### Cálculo para la Proporción

Se utiliza cuando se desea estimar un porcentaje o proporción ($p$).
$$
n = \frac{Z^2 \cdot p(1-p)}{e^2}
$$
Donde:
* $Z$: Valor crítico asociado al nivel de confianza.
* $p$: Proporción poblacional esperada (si se desconoce, se usa $p=0.5$ para maximizar el tamaño de muestra.
* $e$: Margen de error expresado como proporción, usualmente $0.05$

### Cálculo para Fines de Inferencia Exploratoria (Potencia)

Para la inferencia exploratoria (pruebas de hipótesis), el tamaño de muestra se calcula para asegurar la **potencia** adecuada, minimizando el **Error de Tipo II ($\beta$)**. Este cálculo debe considerar la magnitud del efecto.

#### Cálculo Básico para la Media (Potencia)

El cálculo se realiza para detectar una diferencia mínima esperada ($\mu_1 - \mu_0$, la magnitud del efecto) con una potencia deseada ($1-\beta$) y un nivel de significación $\alpha$.

$$
n = \frac{(Z_{\alpha/2} + Z_{\beta})^2 \cdot \sigma^2}{(\mu_1 - \mu_0)^2}
$$
Donde:

* $Z_{\alpha/2}$: Valor Z asociado al nivel de significación ($\alpha$).
* $Z_{\beta}$: Valor Z asociado a la probabilidad del Error de Tipo II ($\beta$).
* $(\mu_1 - \mu_0)$: La magnitud mínima del efecto (diferencia clínicamente significativa) que se espera detectar.

## Referencias