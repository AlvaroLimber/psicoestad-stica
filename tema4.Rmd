# Herramientas estadísticas

Recordar los pasos en las pruebas de hipótesis

1.  **Formular Hipótesis ($H_0$ y $H_a$)**
2.  **Establecer Nivel de Significación ($\alpha$)**
3.  **Construir el Estadístico de Prueba**
4.  **Evaluar y Concluir**

El *p*-valor es una medida que permite evaluar la evidencia en contra de una hipótesis nula. Representa la probabilidad de obtener un resultado tan extremo (o más) que el observado, asumiendo que la hipótesis nula es verdadera. Un *p*-valor pequeño indica que los datos son poco compatibles con la hipótesis nula y sugiere evidencia a favor de la alternativa.

## Análisis de datos categóricos: prueba $\chi^2$

Cuando las variables son **categóricas** (nominales u ordinales), la información se resume en términos de **frecuencias**.  
La **prueba chi-cuadrado ($\chi^2$)** permite evaluar si las frecuencias observadas difieren de las que esperaríamos bajo una hipótesis teórica.  
Es una de las herramientas más utilizadas en psicología para analizar respuestas en categorías o preferencias [@LSJ2025].

### Prueba de bondad de ajuste

Evalúa si las frecuencias observadas en una variable categórica **se ajustan a un modelo teórico** o distribución esperada.

- Hipótesis

$$
H_0: \text{Las frecuencias observadas se ajustan a las frecuencias esperadas.}\\
H_1: \text{Las frecuencias observadas difieren significativamente de las esperadas.}
$$

- Estadístico

$$
\chi^2_0 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}
$$

donde:  
- $O_i$: frecuencia observada,  
- $E_i$: frecuencia esperada bajo \(H_0\),  
- $k$: número de categorías.  

Los **grados de libertad** se calculan como $gl = k - 1$.  
El valor de $\chi^2$ se compara con la distribución chi-cuadrado con esos grados de libertad.

- Decisión

Se rechaza la H0 si:

$$\chi^2_0> \chi^2_{\alpha, k-1}$$

#### Ejemplo

Un psicólogo evalúa si las preferencias por cuatro tipos de música (pop, rock, clásica, jazz) se distribuyen uniformemente.  
Las frecuencias observadas son (30, 25, 20, 25) y las esperadas, si no hubiera preferencia, serían iguales (25 cada una):

\[
\chi^2 = \frac{(30-25)^2}{25} + \frac{(25-25)^2}{25} + \frac{(20-25)^2}{25} + \frac{(25-25)^2}{25} = 2
\]

Con \(gl = 3\) y $\alpha = 0.05$, el valor crítico es 7.815.  
Como 2 < 7.815, **no se rechaza $H_0$** → no hay evidencia de diferencia significativa en las preferencias.

Usando el p-valor (JASP)

Si $p < \alpha$, se concluye que las frecuencias **no se ajustan** al modelo teórico.  
Si $p \ge \alpha$, las diferencias observadas son compatibles con la hipótesis nula.  
La prueba evalúa el **grado de ajuste**, no la dirección del efecto [@LSJ2025].

### Prueba de independencia

Evalúa si **dos variables categóricas están asociadas** o son **independientes**.  
Se trabaja con una **tabla de contingencia** de tamaño $r \times c$.

- Hipótesis

$$
H_0: \text{Las variables son independientes.}\\
H_1: \text{Existe asociación entre las variables.}
$$

- Estadístico de Prueba

$$
\chi^2_0 = \sum_{i=1}^{r}\sum_{j=1}^{c} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$
Donde

$$
E_{ij} = \frac{(F_{i\cdot})(F_{\cdot j})}{n}
$$

donde $F_{i\cdot}$ y $F_{\cdot j}$ son los totales marginales por fila y columna, respectivamente, y $n$ es el total general.

Los grados de libertad son: $gl = (r-1)(c-1)$

- Decisión

Se rechaza H0 si:

$$\chi^2_0> \chi^2_{\alpha, (r-1)(c-1)}$$

#### Ejemplo

Se evalúa si el **género (hombre/mujer)** está asociado con la **preferencia de horario (mañana/tarde)** en 100 estudiantes:

|               | Mañana | Tarde | Total |
|---------------|:------:|:-----:|:-----:|
| Hombre        | 20     | 30    | 50    |
| Mujer         | 10     | 40    | 50    |
| **Total**     | 30     | 70    | 100   |

Frecuencia esperada para la celda (Hombre, Mañana):  

$$
E_{11} = \frac{(50)(30)}{100} = 15
$$

El estadístico $\chi^2$ calculado es 6.67 con $gl = 1$.   El valor crítico a $\alpha = 0.05$ es 3.84 →  **se rechaza $H_0$**, concluyendo que el género y la preferencia de horario están asociados.

### Consideraciones y recomendaciones prácticas

- Cada frecuencia esperada debe ser al menos **5** para la validez de la prueba.  
- En tablas 2×2 puede aplicarse la **corrección de continuidad de Yates**.  
- Si hay celdas pequeñas, se puede usar la **prueba exacta de Fisher**.  
- La prueba $\chi^2$ **no indica la magnitud de la asociación**, solo su existencia.  
- Para cuantificarla, se pueden usar medidas derivadas como el **V de Cramer** o el **coeficiente de contingencia (C)**.

*Ejemplo interpretativo:*  
En un estudio sobre estilos de afrontamiento y género, se obtiene $\chi^2(2) = 10.5$, p < .01.  
Esto sugiere una relación significativa entre el género y el estilo de afrontamiento.

---

### Resumen comparativo

| Tipo de prueba             | Propósito principal                  | Hipótesis nula ($H_0$) | Grados de libertad | Ejemplo típico |
|-----------------------------|--------------------------------------|------------------------|-------------------|----------------|
| **Bondad de ajuste**        | Contrastar una distribución observada con una esperada | Los datos siguen la distribución teórica | \(k - 1\) | Preferencia por tipos de música |
| **Independencia**           | Evaluar asociación entre dos variables categóricas | Las variables son independientes | \((r-1)(c-1)\) | Asociación entre género y estilo de afrontamiento |

---

> La prueba $\chi^2$ es una herramienta flexible y esencial para el análisis de datos categóricos.  
> Su interpretación debe complementarse con medidas de tamaño del efecto y con la inspección de las tablas de contingencia [@LSJ2025; @Moore2013].


> Nota: Cramér's V

Mide el nivel de asociación entre dos variables cualitativas.

$$V=\sqrt{\frac{\chi^2_0}{n*(k-1)}}$$

Donde $k$ es el mínimo entre el número de clases de la variable fila y la variable columna. Sobre la lectura:

  - Si $V\rightarrow 0$ Asociación débil
  - Si $V\rightarrow 1$ Asociación fuerte

## Comparación de dos medias: pruebas z, t y no paramétricas

En investigación psicológica y social es común comparar **las medias de dos grupos** o condiciones (por ejemplo, comparar niveles de ansiedad entre hombres y mujeres, o antes y después de una intervención).  
El objetivo es determinar si las diferencias observadas reflejan una diferencia real en la población o son producto del azar [@LSJ2025; @Moore2013].


Las tres pruebas más comunes son:

1. **z-test** → cuando se conoce la varianza poblacional (caso teórico).  
2. **t-test** → cuando la varianza poblacional es desconocida (caso real).  
3. **Pruebas no paramétricas** → cuando los datos no cumplen los supuestos de normalidad o escala de intervalo.

### Prueba z para dos medias (caso teórico)

Se aplica cuando:
- la variable es cuantitativa continua,  
- las observaciones son independientes,  
- y se **conocen las desviaciones estándar poblacionales**.

#### Hipótesis

$$
H_0: \mu_1 = \mu_2\\
H_1: \mu_1 \neq \mu_2
$$

#### Estadístico

$$
z_0 = \frac{(\bar{X}_1 - \bar{X}_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}
$$

El estadístico $z_0$ sigue una distribución normal estándar \(N(0,1)\).

#### Ejemplo

Un investigador quiere comparar los tiempos de reacción de dos grupos de participantes en una tarea cognitiva.  
Si las medias son 520 ms y 540 ms, con desviaciones poblacionales conocidas de 50 y 60 ms, y n=30 por grupo:

\[
z_0 = \frac{520 - 540}{\sqrt{\frac{50^2}{30} + \frac{60^2}{30}}} = -1.44
\]

Como $|z_0| = 1.44 < 1.96$, **no se rechaza $H_0$** (no hay evidencia suficiente de diferencia significativa).

### Prueba t para dos medias

En la práctica, las varianzas poblacionales **no son conocidas**, por lo que se emplea la **distribución t de Student**.  
Existen dos tipos principales:

1. **t para muestras independientes**  
2. **t para muestras relacionadas (dependientes o pareadas)**


#### t para muestras independientes

Se aplica cuando se comparan dos grupos distintos.

**Hipótesis:**

\[
H_0: \mu_1 = \mu_2 \quad \text{vs.} \quad H_1: \mu_1 \neq \mu_2
\]

**Estadístico:**

\[
t = \frac{(\bar{X}_1 - \bar{X}_2)}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
\]

donde \(s_p\) es la **desviación estándar combinada**:

\[
s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}
\]

**Grados de libertad:** \(gl = n_1 + n_2 - 2\)

**Ejemplo:**

En un estudio sobre estrés académico, dos grupos de estudiantes (n=25 cada uno) obtienen medias de 35.4 y 40.1 puntos, con desviaciones estándar de 8.2 y 7.6.

\[
t = \frac{35.4 - 40.1}{\sqrt{\frac{(8.2^2 + 7.6^2)}{2} \cdot (\frac{1}{25} + \frac{1}{25})}} = -2.13
\]

Con \(gl = 48\) y $\alpha = 0.05$, el valor crítico es ±2.01 →  
**se rechaza $H_0$** → diferencia significativa de estrés entre grupos.

#### t para muestras relacionadas

Se aplica cuando las observaciones provienen de los **mismos participantes** medidos dos veces (pretest–postest, condiciones A/B).

**Hipótesis:**

\[
H_0: \mu_D = 0
\]

donde \(\mu_D\) es la media de las diferencias.

**Estadístico:**

\[
t = \frac{\bar{D}}{s_D / \sqrt{n}}
\]

**Ejemplo:**

Un grupo de 20 personas completa un test de ansiedad antes y después de una intervención.  
La media de las diferencias (pre–post) es 4.2 con $s_D = 6.0$.

\[
t = \frac{4.2}{6.0/\sqrt{20}} = 3.13
\]

Con \(gl = 19\), el valor crítico a $\alpha = 0.05$ (bilateral) es 2.09 →  
**se rechaza $H_0$**, indicando una reducción significativa en ansiedad.


### Supuestos de las pruebas t

- Escala de intervalo o razón.  
- Normalidad de la variable en cada grupo.  
- Homogeneidad de varianzas (para muestras independientes).  
- Independencia entre observaciones.

Cuando alguno de estos supuestos no se cumple, se recurre a pruebas **no paramétricas**.


### Pruebas no paramétricas equivalentes

Las pruebas no paramétricas no requieren normalidad ni homocedasticidad, y se aplican sobre rangos o signos.

| Tipo de comparación | Prueba paramétrica | Prueba no paramétrica | Variable | Ejemplo psicológico |
|---------------------:|:------------------:|:----------------------:|:---------|:--------------------|
| Dos grupos independientes | t de Student | Mann–Whitney U | Ordinal / No normal | Comparar puntajes de ansiedad entre grupos experimentales |
| Dos grupos relacionados | t pareada | Wilcoxon de rangos con signo | Ordinal / No normal | Evaluar cambio pre–post en autoeficacia |

*Ejemplo:*  
En un estudio sobre satisfacción laboral antes y después de una capacitación (escala ordinal), se aplica la **prueba de Wilcoxon**:  
$W = 15$, p = .02 → diferencia significativa entre las mediciones.

### Interpretación y tamaño del efecto

La significación estadística indica si la diferencia es real,  
pero **no informa sobre su magnitud**.  
Por ello se recomienda reportar siempre el **tamaño del efecto**.

#### d de Cohen

\[
d = \frac{\bar{X}_1 - \bar{X}_2}{s_p}
\]

Interpretación general [@Cohen1994]:

| d | Magnitud del efecto |
|---|---------------------|
| 0.2 | Pequeño |
| 0.5 | Mediano |
| 0.8 | Grande |

*Ejemplo:*  
Si $\bar{X}_1 - \bar{X}_2 = 5$ y $s_p = 10$, entonces $d = 0.5$ → efecto **moderado**.

> Notas:

> Las pruebas z, t y sus equivalentes no paramétricas permiten contrastar diferencias entre medias bajo distintos supuestos.  
> En psicología y ciencias sociales, su interpretación debe acompañarse del **p-valor**, el **tamaño del efecto (d)** y, cuando sea posible, un **intervalo de confianza** para la diferencia [@LSJ2025; @Cohen1994].


## Correlación y regresión lineal 

## Comparar varias medias: ANOVA de una vía

## ANOVA factorial y ANCOVA